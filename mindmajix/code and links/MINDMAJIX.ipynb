{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba324d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\v3s\\appdata\\roaming\\python\\python39\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\v3s\\appdata\\roaming\\python\\python39\\site-packages (from selenium) (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\program files\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from openpyxl import load_workbook\n",
    "import dateutil.parser as parser\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "driver=webdriver.Chrome(\"C:/Users/V3S/Downloads/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "597d428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import dateutil.parser as parser\n",
    "\n",
    "def mindmajix_CMS():\n",
    "\n",
    "  URLS=[\"https://mindmajix.com/sql-server-training\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  title=[]\n",
    "  short_desc=[]\n",
    "  video_url=[]\n",
    "  description=[]\n",
    "  what_will_learn=[]\n",
    "  skills_gained=[]\n",
    "  price=[]\n",
    "  skills2=[]\n",
    "  target_students=[]\n",
    "  level=[]\n",
    "  urls=[]\n",
    "  duration=[]\n",
    "  avg_salary=[]\n",
    "  job_assistance=[]\n",
    "  total_duration_unit=[]\n",
    "  instruction_type=[]\n",
    "  pricing_type=[]\n",
    "  prerequisites=[]\n",
    "  what_will_learn=[]\n",
    "  currency=[]\n",
    "  languages=[]\n",
    "  live_class=[]\n",
    "  capstone_project=[]\n",
    "\n",
    "  instructor=[]\n",
    "  instructor_bio=[]\n",
    "  accessibilities=[]\n",
    "  delivery_method=[]\n",
    "  instruction_type=[]\n",
    "  reviewer_name_1=[]\n",
    "  reviewer_name_2=[]\n",
    "  reviewer_name_3=[]\n",
    "  reviewer_name_4=[]\n",
    "  reviewer_photo_1=[]\n",
    "  reviewer_photo_2=[]\n",
    "  reviewer_photo_3=[]\n",
    "  reviewer_photo_4=[]\n",
    "  review_1=[]\n",
    "  review_2=[]\n",
    "  review_3=[]\n",
    "  review_4=[]\n",
    "  batch_start_date_1=[]\n",
    "  content=[]\n",
    "\n",
    "  for url in URLS:\n",
    "    try:\n",
    "      r=requests.get(url)\n",
    "      soup=BeautifulSoup(r.content,\"html.parser\")\n",
    "    except:\n",
    "      time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(15)\n",
    "        con=[]\n",
    "        driver.find_element_by_id(\"read-curriculum\").click()\n",
    "        c=driver.find_elements_by_class_name(\"Curriculum_accordian_title__3GyxV\")\n",
    "        for i in c:\n",
    "            con.append(i.text)\n",
    "        content.append(con)\n",
    "    except:\n",
    "        content.append(\"NaN\")\n",
    "\n",
    "    #url\n",
    "    urls.append(url)\n",
    "\n",
    "\n",
    "    #title\n",
    "    try:\n",
    "      titles=soup.find(\"h1\").text\n",
    "      title.append(titles)\n",
    "    except:\n",
    "      title.append(\"NaN\")\n",
    "\n",
    "    #short_desc\n",
    "    try:\n",
    "      short=soup.find(\"p\",class_=\"Banner_caption__c2YJu\").text\n",
    "      short_desc.append(short)\n",
    "    except:\n",
    "      short_desc.append(\"NaN\")\n",
    "\n",
    "    #course_description\n",
    "    try:\n",
    "      desc=soup.find(\"div\",class_=\"Curriculum_description__1LwKr\")\n",
    "      description.append(desc)\n",
    "    except:\n",
    "      description.append(\"NaN\")\n",
    "\n",
    "    #duration\n",
    "    try:\n",
    "      dur=soup.find(\"p\",class_=\"Curriculum_course_feature_text__1DRlP\").text.replace(\" Hours of Sessions\",\"\")\n",
    "      duration.append(dur)\n",
    "    except:\n",
    "      duration.append(\"NaN\")\n",
    "\n",
    "    #total_duration_unit\n",
    "    total_duration_unit.append(\"Hours\")\n",
    "\n",
    "    #avg_Salary\n",
    "    try:\n",
    "      salary=soup.findAll(\"p\",class_=\"Projects_info_detail__2Tnio\")[1].text\n",
    "      avg_salary.append(salary)\n",
    "    except:\n",
    "      avg_salary.append(\"NaN\")\n",
    "\n",
    "    #job_assistance\n",
    "    job_assistance.append(\"TRUE\")\n",
    "\n",
    "\n",
    "    #instructor\n",
    "    try:\n",
    "      ins=soup.find(\"td\",class_=\"Instructor_table_element__2V-BL\").text\n",
    "      instructor.append(ins)\n",
    "    except:\n",
    "      instructor.append(\"NaN\")\n",
    "\n",
    "    #instrcutor_bio\n",
    "    try:\n",
    "      ins_bio=soup.findAll(\"td\",class_=\"Instructor_table_element__2V-BL\")[3].text\n",
    "      instructor_bio.append(ins_bio)\n",
    "    except:\n",
    "      instructor_bio.append(\"NaN\")\n",
    "\n",
    "    #target_students\n",
    "\n",
    "    try:\n",
    "      target=soup.findAll(\"div\",class_=\"course_objectives_card__3uPcY card\")[2].find(\"ul\").text.replace(\"\\n\",\"|\")\n",
    "      target_students.append(target)\n",
    "    except:\n",
    "      target_students.append(\"NaN\")\n",
    "\n",
    "    #prerequisites\n",
    "    try:\n",
    "      pre=soup.findAll(\"div\",class_=\"course_objectives_card__3uPcY card\")[3].text\n",
    "      prerequisites.append(pre)\n",
    "    except:\n",
    "      prerequisites.append(\"NaN\")\n",
    "\n",
    "    #what_will_learn\n",
    "    try:\n",
    "      learn=soup.findAll(\"div\",class_=\"course_objectives_card__3uPcY card\")   [4].find(\"ul\").text.replace(\"\\n\",\"|\").replace(\".\",\"\")\n",
    "      what_will_learn.append(learn)\n",
    "    except:\n",
    "      what_will_learn.append(\"NaN\")\n",
    "\n",
    "    #reviewer_name_1\n",
    "    try:\n",
    "      name1=soup.findAll(\"p\",class_=\"Reviews_character_name__2X1QF\")[0].text\n",
    "      reviewer_name_1.append(name1)\n",
    "    except:\n",
    "      reviewer_name_1.append(\"NaN\")\n",
    "\n",
    "    #reviewer_photo_1\n",
    "    try:\n",
    "      photo1=soup.findAll(\"div\",class_=\"col-lg-3 col-md-3 col-sm-3 col-3\")[0].find(\"img\")['src']\n",
    "      reviewer_photo_1.append(photo1)\n",
    "    except:\n",
    "      reviewer_photo_1.append(\"NaN\")\n",
    "\n",
    "    #reviewer_name_2\n",
    "    try:\n",
    "      name2=soup.findAll(\"p\",class_=\"Reviews_character_name__2X1QF\")[1].text\n",
    "      reviewer_name_2.append(name2)\n",
    "    except:\n",
    "      reviewer_name_2.append(\"NaN\")\n",
    "\n",
    "    #reviewer_photo_2\n",
    "    try:\n",
    "      photo2=soup.findAll(\"div\",class_=\"col-lg-3 col-md-3 col-sm-3 col-3\")[1].find(\"img\")['src']\n",
    "      reviewer_photo_2.append(photo2)\n",
    "    except:\n",
    "      reviewer_photo_2.append(\"NaN\")\n",
    "\n",
    "    #reviewer_name_3\n",
    "    try:\n",
    "      name3=soup.findAll(\"p\",class_=\"Reviews_character_name__2X1QF\")[2].text\n",
    "      reviewer_name_3.append(name3)\n",
    "    except:\n",
    "      reviewer_name_3.append(\"NaN\")\n",
    "\n",
    "    #reviewer_photo_3\n",
    "    try:\n",
    "      photo3=soup.findAll(\"div\",class_=\"col-lg-3 col-md-3 col-sm-3 col-3\")[2].find(\"img\")['src']\n",
    "      reviewer_photo_3.append(photo3)\n",
    "    except:\n",
    "      reviewer_photo_3.append(\"NaN\")\n",
    "\n",
    "    #reviewer_name_4\n",
    "    try:\n",
    "      name4=soup.findAll(\"p\",class_=\"Reviews_character_name__2X1QF\")[3].text\n",
    "      reviewer_name_4.append(name4)\n",
    "    except:\n",
    "      reviewer_name_4.append(\"NaN\")\n",
    "\n",
    "    #reviewer_photo_4\n",
    "    try:\n",
    "      photo4=soup.findAll(\"div\",class_=\"col-lg-3 col-md-3 col-sm-3 col-3\")[3].find(\"img\")['src']\n",
    "      reviewer_photo_4.append(photo4)\n",
    "    except:\n",
    "      reviewer_photo_4.append(\"NaN\")\n",
    "\n",
    "\n",
    "\n",
    "    #review_1\n",
    "    try:\n",
    "      rev1=soup.find('p', class_=\"Reviews_testimonial_text__3EfIq\").find(\"span\").text\n",
    "      review_1.append(rev1)\n",
    "    except:\n",
    "      review_1.append(\"NaN\")\n",
    "\n",
    "    #review_2\n",
    "    try:\n",
    "      rev2=soup.findAll('p', class_=\"Reviews_testimonial_text__3EfIq\")[1].find(\"span\").text\n",
    "      review_2.append(rev2)\n",
    "    except:\n",
    "      review_2.append(\"NaN\")\n",
    "\n",
    "    #review_3\n",
    "    try:\n",
    "      rev3=soup.findAll('p', class_=\"Reviews_testimonial_text__3EfIq\")[2].find(\"span\").text\n",
    "      review_3.append(rev3)\n",
    "    except:\n",
    "      review_3.append(\"NaN\")\n",
    "\n",
    "    #review_4\n",
    "    try:\n",
    "      rev4=soup.findAll('p', class_=\"Reviews_testimonial_text__3EfIq\")[3].find(\"span\").text\n",
    "      review_4.append(rev4)\n",
    "    except:\n",
    "      review_4.append(\"NaN\")\n",
    "\n",
    "\n",
    "\n",
    "    #delivery_method\n",
    "    delivery_method.append(\"Online\")\n",
    "\n",
    "    #instruction_type\n",
    "    instruction_type.append(\"Instructor Paced\")\n",
    "\n",
    "    #languages\n",
    "    languages.append(\"English\")\n",
    "\n",
    "    #accessibilities\n",
    "    accessibilities.append(\"Mobile,Desktop\")\n",
    "\n",
    "    #live_class\n",
    "    live_class.append(\"TRUE\")\n",
    "\n",
    "    #capstone_project\n",
    "    capstone_project.append(\"TRUE\")\n",
    "\n",
    "    df=pd.DataFrame.from_dict({\n",
    "          'page_url' : urls,\n",
    "\n",
    "                                            'title': title,\n",
    "\n",
    "                                            'description': description,\n",
    "                                            'delivery_method': delivery_method,\n",
    "                                            'instruction_type' :  instruction_type,\n",
    "                                            'what_will_learn': what_will_learn,\n",
    "                                            'prerequisites':prerequisites,\n",
    "                                            'target_students': target_students,\n",
    "                                            'instructor|1|name': instructor,\n",
    "                                            'instructor_bio':instructor_bio,\n",
    "                                            'review|1|reviewer_name': reviewer_name_1,\n",
    "                                            'review|1|photo':reviewer_photo_1,\n",
    "                                            'review|1|review':review_1,\n",
    "                                            'review|2|reviewer_name': reviewer_name_2,\n",
    "                                            'review|2|photo':reviewer_photo_2,\n",
    "                                            'review|2|review':review_2,\n",
    "                                            'review|3|reviewer_name': reviewer_name_3,\n",
    "                                            'review|3|photo':reviewer_photo_3,\n",
    "                                            'review|3|review':review_3,\n",
    "                                            'review|4|reviewer_name': reviewer_name_4,\n",
    "                                            'review|4|photo':reviewer_photo_4,\n",
    "                                            'review|4|review':review_4,\n",
    "                                            'languages' : languages,\n",
    "                                            'total_duration':duration,\n",
    "                                            'total_duration_unit':total_duration_unit,\n",
    "                                        'content':content,\n",
    "\n",
    "                                            'short_description': short_desc,\n",
    "                                            'accessibilities' : accessibilities,\n",
    "                                            'live_class':live_class,\n",
    "                                            'job_assistance':job_assistance,\n",
    "                                            'capstone_project':capstone_project,\n",
    "                                            'average_salary':avg_salary         \n",
    "\n",
    "\n",
    "          }, orient='index')\n",
    "\n",
    "\n",
    "\n",
    "    df = df.transpose()\n",
    "    df.to_csv(\"mindmajix_database_programming.csv\", index=False)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    mindmajix_CMS()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
